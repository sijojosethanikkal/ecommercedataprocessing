{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e173f77-4847-4a02-8b54-f5480d7b7c53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# E-commerce Sales Data Processing with Databricks\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook gives you the data processing for E-commerce platform\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The required files for this project are stored in an Amazon S3 bucket.\n",
    "\n",
    "## Program Exit Conditions\n",
    "\n",
    "The program will exit in the following cases:\n",
    "\n",
    "1. **File Not Present**: The program will exit if the required file is not present in the S3 bucket.\n",
    "\n",
    "2. **Empty File Data**: The program will exit if the entire file data is empty.\n",
    "\n",
    "## Running the Program\n",
    "\n",
    "Ensure that the required files are present and not empty in the S3 bucket before running the program.\n",
    "## Approach.\n",
    "1. Read all the files.\n",
    "2. Since the approach is to analysis on top of the files. I had created a master dataframe and create valuable insights from the data frame.\n",
    "\n",
    "## Assumptions\n",
    "1. In order to read the execl file. The `com.crealytics.spark.excel` should be available in databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64990c63-51a9-4d4d-92cd-0d5718083de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Libraries to load\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, LongType, TimestampType\n",
    "import sys\n",
    "from pyspark.sql.functions import col, to_date,regexp_extract\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2359ef-9196-4e84-bce2-6ebce605a033",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order Schema\n",
    "order_schema = StructType([\n",
    "    StructField(\"Row ID\", LongType()),\n",
    "    StructField(\"Order ID\", StringType()),\n",
    "    StructField(\"Order Date\", StringType()),\n",
    "    StructField(\"Ship Date\", StringType()),\n",
    "    StructField(\"Ship Mode\", StringType()),\n",
    "    StructField(\"Customer ID\", StringType()),\n",
    "    StructField(\"Product ID\", StringType()),\n",
    "    StructField(\"Quantity\", LongType()),\n",
    "    StructField(\"Price\", StringType()),\n",
    "    StructField(\"Discount\", DoubleType()),\n",
    "    StructField(\"Profit\", DoubleType())\n",
    "])\n",
    "# customer Schema\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Customer ID\", StringType()),\n",
    "    StructField(\"Customer Name\", StringType()),\n",
    "    StructField(\"email\", StringType()),\n",
    "    StructField(\"phone\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"Segment\", StringType()),\n",
    "    StructField(\"Country\", IntegerType()),  \n",
    "    StructField(\"City\", StringType()),\n",
    "    StructField(\"State\", StringType()),\n",
    "    StructField(\"Postal Code\", StringType()),\n",
    "    StructField(\"Region\", StringType())\n",
    "])\n",
    "#product Schema\n",
    "product_schema = StructType([\n",
    "    StructField(\"Product ID\", StringType()),\n",
    "    StructField(\"Category\", StringType()),\n",
    "    StructField(\"Sub-Category\", StringType()),\n",
    "    StructField(\"Product Name\", StringType()),\n",
    "    StructField(\"State\", StringType()),\n",
    "    StructField(\"Price per product\", DoubleType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac1bc60-2ec9-40bb-a62b-9e6297d64300",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read s3 files from input paramters\n",
    "dbutils.widgets.text(\"order_file\",\"s3://ecomerce/Order.json\")\n",
    "dbutils.widgets.text(\"customer_file\",\"s3://ecomerce/customer.xlsx\")\n",
    "dbutils.widgets.text(\"product_file\",\"s3://ecomerce/product.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7276c9c-8bbd-4fad-bb8f-2f9760d0c93c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retriive from paramters\n",
    "order_file = dbutils.widgets.get(\"order_file\")\n",
    "customer_file = dbutils.widgets.get(\"customer_file\")\n",
    "product_file = dbutils.widgets.get(\"product_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52e75fe3-f1b5-48a8-b26e-7c1fd5faf77f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load order data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2cda398-9449-4d94-bdff-8c8646b05e8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read JSON data with explicit schema.\n",
    "    order_df = spark.read.option(\"multiLine\", \"true\").schema(order_schema).json(order_file)\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading JSON order data. Please check!. Error: \", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce6e9fca-9a36-4a9d-958e-803918c25f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check for any error in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e5d40f5-4f79-40a2-85d6-06b336c7c8d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chek the data frame is totaly empty\n",
    "if order_df.isEmpty():\n",
    "  print(\"order data frame is empty\")\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c55e1799-bb93-4409-8b75-83fa3847d480",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "for column in order_df.columns:\n",
    "    if order_df.select(col(column)).filter(col(column).isNull()).count() == order_df.count():\n",
    "        logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebed148b-1257-4cd8-aacb-b7e2fa18b525",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Conversion of columns from string to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8afd97-22ab-4f82-9e82-b482404511ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for any misisng rows in data frames.\n",
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Order Date\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Order date column has missing data: {e}. Number of rows: {filtered_df.count()}\")\n",
    "\n",
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Ship Date\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Ship Date column has missing data: {e}. Number of rows: {filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "424b9336-68c0-4396-9618-7938710f2dfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Convert date strings to Timestamps\n",
    "    order_df = order_df.withColumn(\"Order Date\", to_date(col(\"Order Date\"), \"dd/MM/yyyy\"))\n",
    "    order_df = order_df.withColumn(\"Ship Date\", to_date(col(\"Ship Date\"), \"dd/MM/yyyy\"))\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Date conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d65fe366-f235-4785-819c-5275ee43f1c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Convert Price column from strings to double\n",
    "    order_df = order_df.withColumn(\"Price\", col(\"Price\").cast(\"double\"))\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Price column conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10101b01-9da1-4db7-8885-904c398814e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Price\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Price column has missing data: {e}. Number of rows: {filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22f7d22e-aed3-4707-a0bc-9b2a7cb9418d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load customer data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b5549e8-095d-4e6e-8a12-c204ae475b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read xslx data with explicit schema.\n",
    "    customer_df = spark.read.format(\"com.crealytics.spark.excel\").option(\"header\", \"true\").schema(custom_schema).load(customer_file)\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading execl customer data. Please check!. Error: \", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1e35c88-3f44-49ca-897e-d522ec98c00d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check for amy error in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe5ffaaf-a635-471e-bb14-9550f29eb619",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chek the data frame is totaly empty\n",
    "if customer_df.isEmpty():\n",
    "  print(\"customer data frame is empty\")\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88659091-04c3-4e63-8f75-4dc01fd60d48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "for column in customer_df.columns:\n",
    "    if customer_df.select(col(column)).filter(col(column).isNull()).count() == order_df.count():\n",
    "        logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aff7199-0c71-4e52-bfa6-cc64070240c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load product data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ff38a7f-d47c-477c-a801-0b89a7116f72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read csv data with explicit schema.\n",
    "    product_df = spark.read.csv(product_csv, header=True, schema=product_schema)\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading product csv data. Please check!. Error: \", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9a42ad3-be4e-40b2-991e-a80607c83eae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check for any error in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a92e291-677e-41cf-b5dc-9501357bd403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chek the data frame is totaly empty\n",
    "if product_df.isEmpty():\n",
    "  print(\"product data frame is empty\")\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b84e90bf-bec2-49fc-a91e-519a90aed323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "for column in product_df.columns:\n",
    "    if product_df.select(col(column)).filter(col(column).isNull()).count() == product_df.count():\n",
    "        logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44a954a9-36e2-42c0-beea-2637dd0f7a6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create a master data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b403e50-eed8-4241-ad32-e90d4da21931",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "master_df = order_df.join(customer_df, on=\"Customer ID\", how=\"inner\").join(product_df, on=\"Product ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6a38b1-8579-4692-bbc7-a76979920913",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an enriched table for customers and products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f4177c4-e5c0-4965-a1c4-a2767eb0dd76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by \"Customer Name\" and \"Product Name\" and count occurrences\n",
    "customer_product_counts = master_df.groupBy(\"Customer Name\", \"Product Name\").count()\n",
    "\n",
    "# Add a new column for the count\n",
    "customer_product_counts = customer_product_counts.withColumn(\"Count\", F.col(\"count\"))\n",
    "customer_product_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aa9674a-d73c-4786-ab6f-bf5265b38f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an enriched table which has\n",
    "1. order information \n",
    "    1. Profit rounded to 2 decimal places\n",
    "2. Customer name and country\n",
    "3. Product category and sub category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9beaa6aa-af98-47c0-93a1-a2c9b6c77231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "order_info = master_df.select('Order ID','Profit','Customer Name','Country','Category','Sub-Category')\n",
    "order_info.show()\n",
    "order_info = order_info.select(round(order_info[\"Profit\"], 2).alias(\"Profit\"))\n",
    "order_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dbf62d8-3adc-413c-8485-2077a449c22f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an aggregate table that shows profit by \n",
    "1. Year\n",
    "2. Product Category\n",
    "3. Product Sub Category\n",
    "4. Customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "408f5e08-9198-4ae2-a952-55e6bd4703de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "master_df = master_df.withColumn(\"year\", year(\"Order Date\"))\n",
    "agg_df = master_df.withColumn(\"year\", year(\"Order Date\"))\n",
    "agg_df = agg_df.groupBy(\"year\",\"Category\", \"Sub-Category\", \"Customer Name\").sum(\"Profit\")\n",
    "\n",
    "agg_df = agg_df.withColumnRenamed(\"sum(Profit)\", \"Profit\")\n",
    "agg_df = agg_df.withColumn(\"Profit\", round(col(\"Profit\"), 2))\n",
    "agg_df = agg_df.orderBy(\"year\")\n",
    "\n",
    "agg_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dfd4d83-e1d5-40f6-b8aa-f32cb7117ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using SQL output the following aggregates\n",
    "1. Profit by Year\n",
    "2. Profit by Year + Product Category\n",
    "3. Profit by Customer\n",
    "4. Profit by Customer + Year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56f4cfbe-4db8-4996-9c73-ec14a80b2b68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586d2051-5dcb-4366-a442-ba3c83e30633",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the master_df as a temporary table\n",
    "master_df.createOrReplaceTempView(\"master_table\")\n",
    "\n",
    "# Query the master_table to get Profit by Year\n",
    "profit_by_year_df = spark.sql(\"SELECT year, ROUND(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY year ORDER BY year\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "profit_by_year_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cfcc73f-680a-41cd-8ff8-c40942ff43a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Year + Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c47e95e-8709-4769-89bf-b7df8a5fc0cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_year_category_df = spark.sql(\"SELECT year, Category, ROUND(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY year, Category ORDER BY year, Category\")\n",
    "\n",
    "profit_by_year_category_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c509621-73d5-4454-912f-fcbbfe76db4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fbc19ef-1631-4b4b-ade0-f6233da78d7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_customer_df = spark.sql(\"SELECT `Customer Name`, Round(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY `Customer Name` order by TotalProfit DESC\")\n",
    "profit_by_customer_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd48412-c616-4d3c-8731-7e08fdf66293",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Customer + Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba6b2922-55c0-4809-a2d8-b089fec5bba8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_customer_year_df = spark.sql(\"SELECT `Customer Name`, year, Round(SUM(Profit), 2) AS TotalProfit FROM master_table GROUP BY `Customer Name`, year ORDER BY year, TotalProfit DESC\")\n",
    "\n",
    "profit_by_customer_year_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ecommerce_sale_data",
   "widgets": {
    "customer_file": {
     "currentValue": "s3://ecomerce/customer.xlsx",
     "nuid": "03a0ee5a-29ca-4091-9a81-76c45f019218",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/customer.xlsx",
      "label": null,
      "name": "customer_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "order_file": {
     "currentValue": "s3://ecomerce/Order.json",
     "nuid": "04e427ec-d9a7-488e-85a8-0660a3bfa0ae",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/Order.json",
      "label": null,
      "name": "order_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "product_file": {
     "currentValue": "s3://ecomerce/product.csv",
     "nuid": "e8fdb093-097a-4a5e-8ce4-b61684984210",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/product.csv",
      "label": null,
      "name": "product_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
