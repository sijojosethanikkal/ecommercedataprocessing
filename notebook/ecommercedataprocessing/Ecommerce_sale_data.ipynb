{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e173f77-4847-4a02-8b54-f5480d7b7c53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# E-commerce Sales Data Processing with Databricks\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook gives you the data processing for E-commerce platform\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The required files for this project are stored in an Amazon S3 bucket.\n",
    "\n",
    "## Program Exit Conditions\n",
    "\n",
    "The program will exit in the following cases:\n",
    "\n",
    "1. **File Not Present**: The program will exit if the required file is not present in the S3 bucket.\n",
    "\n",
    "2. **Empty File Data**: The program will exit if the entire file data is empty.\n",
    "\n",
    "## Running the Program\n",
    "\n",
    "Ensure that the required files are present and not empty in the S3 bucket before running the program.\n",
    "## Approach.\n",
    "1. Read all the files.\n",
    "2. Since the approach is to analysis on top of the files. I had created a master dataframe and create valuable insights from the data frame.\n",
    "\n",
    "## Assumptions\n",
    "1. In order to read the execl file. The `com.crealytics.spark.excel` should be available in databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64990c63-51a9-4d4d-92cd-0d5718083de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Libraries to load\n",
    "from ecommerce_functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_date, regexp_extract, round, year\n",
    "from pyspark.sql.types import DoubleType, IntegerType, LongType, StringType, StructField, StructType, TimestampType\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2359ef-9196-4e84-bce2-6ebce605a033",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order Schema\n",
    "order_schema = StructType([\n",
    "    StructField(\"Row ID\", LongType()),\n",
    "    StructField(\"Order ID\", StringType()),\n",
    "    StructField(\"Order Date\", StringType()),\n",
    "    StructField(\"Ship Date\", StringType()),\n",
    "    StructField(\"Ship Mode\", StringType()),\n",
    "    StructField(\"Customer ID\", StringType()),\n",
    "    StructField(\"Product ID\", StringType()),\n",
    "    StructField(\"Quantity\", LongType()),\n",
    "    StructField(\"Price\", StringType()),\n",
    "    StructField(\"Discount\", DoubleType()),\n",
    "    StructField(\"Profit\", DoubleType())\n",
    "])\n",
    "# customer Schema\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Customer ID\", StringType()),\n",
    "    StructField(\"Customer Name\", StringType()),\n",
    "    StructField(\"email\", StringType()),\n",
    "    StructField(\"phone\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"Segment\", StringType()),\n",
    "    StructField(\"Country\", IntegerType()),  \n",
    "    StructField(\"City\", StringType()),\n",
    "    StructField(\"State\", StringType()),\n",
    "    StructField(\"Postal Code\", StringType()),\n",
    "    StructField(\"Region\", StringType())\n",
    "])\n",
    "#product Schema\n",
    "product_schema = StructType([\n",
    "    StructField(\"Product ID\", StringType()),\n",
    "    StructField(\"Category\", StringType()),\n",
    "    StructField(\"Sub-Category\", StringType()),\n",
    "    StructField(\"Product Name\", StringType()),\n",
    "    StructField(\"State\", StringType()),\n",
    "    StructField(\"Price per product\", DoubleType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac1bc60-2ec9-40bb-a62b-9e6297d64300",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read s3 files from input paramters\n",
    "dbutils.widgets.text(\"order_file\",\"s3://ecomerce/Order.json\")\n",
    "dbutils.widgets.text(\"customer_file\",\"s3://ecomerce/customer.xlsx\")\n",
    "dbutils.widgets.text(\"product_file\",\"s3://ecomerce/product.csv\")\n",
    "dbutils.widgets.text(\"outputbucket\",\"ecommerce/output\")\n",
    "dbutils.widgets.dropdown(\"Mode\",\"Test\",[\"Test\",\"Dev\",\"Prod\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7276c9c-8bbd-4fad-bb8f-2f9760d0c93c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retriive from paramters\n",
    "order_file = dbutils.widgets.get(\"order_file\")\n",
    "customer_file = dbutils.widgets.get(\"customer_file\")\n",
    "product_file = dbutils.widgets.get(\"product_file\")\n",
    "outputbucket = dbutils.widgets.get(\"outputbucket\")\n",
    "mode = dbutils.widgets.get(\"Mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52e75fe3-f1b5-48a8-b26e-7c1fd5faf77f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load order data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2cda398-9449-4d94-bdff-8c8646b05e8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read JSON data with explicit schema.\n",
    "    if fileExists(order_file):\n",
    "      order_df = spark.read.option(\"multiLine\", \"true\").schema(order_schema).json(order_file)\n",
    "    if dataframeEmpty(order_df):\n",
    "      print(\"Dataframe is empty\")\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading JSON order data. Please check!. Error: \", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c55e1799-bb93-4409-8b75-83fa3847d480",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "if checkColumnsNull(order_df):\n",
    "    print('Data frame has no empty columns')\n",
    "else:\n",
    "    logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebed148b-1257-4cd8-aacb-b7e2fa18b525",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Conversion of columns from string to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8afd97-22ab-4f82-9e82-b482404511ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for any misisng rows in data frames.\n",
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Order Date\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Order date column has missing data: {e}. Number of rows: {filtered_df.count()}\")\n",
    "\n",
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Ship Date\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Ship Date column has missing data: {e}. Number of rows: {filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "424b9336-68c0-4396-9618-7938710f2dfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Convert date strings to Timestamps\n",
    "    order_df = order_df.withColumn(\"Order Date\", to_date(col(\"Order Date\"), \"dd/MM/yyyy\"))\n",
    "    order_df = order_df.withColumn(\"Ship Date\", to_date(col(\"Ship Date\"), \"dd/MM/yyyy\"))\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Date conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d65fe366-f235-4785-819c-5275ee43f1c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Convert Price column from strings to double\n",
    "    order_df = order_df.withColumn(\"Price\", col(\"Price\").cast(\"double\"))\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Price column conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10101b01-9da1-4db7-8885-904c398814e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filtered_df = order_df.filter(col(\"Price\").isNull())\n",
    "except Exception as e:\n",
    "    # Log the error and the number of rows\n",
    "    logging.warning(f\"Price column has missing data: {e}. Number of rows: {filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22f7d22e-aed3-4707-a0bc-9b2a7cb9418d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load customer data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b5549e8-095d-4e6e-8a12-c204ae475b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read xslx data with explicit schema.\n",
    "    if fileExists(customer_file):\n",
    "      customer_df = spark.read.format(\"com.crealytics.spark.excel\").option(\"header\", \"true\").schema(custom_schema).load(customer_file)\n",
    "    if dataframeEmpty(customer_df):\n",
    "      print(\"Dataframe is empty\")\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading execl customer data. Please check!. Error:\", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88659091-04c3-4e63-8f75-4dc01fd60d48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "if checkColumnsNull(customer_df):\n",
    "    print('Data frame has no empty columns')\n",
    "else:\n",
    "    logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aff7199-0c71-4e52-bfa6-cc64070240c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load product data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ff38a7f-d47c-477c-a801-0b89a7116f72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Read csv data with explicit schema.\n",
    "    if fileExists(product_csv):\n",
    "      product_df = spark.read.csv(product_csv, header=True, schema=product_schema)\n",
    "    if dataframeEmpty(product_df):\n",
    "      print(\"Dataframe is empty\")\n",
    "except Exception as e:\n",
    "  print(\"Error occurred while reading product csv data. Please check!. Error: \", e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b84e90bf-bec2-49fc-a91e-519a90aed323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any column is fully null\n",
    "if checkColumnsNull(product_df):\n",
    "    print('Data frame has no empty columns')\n",
    "else:\n",
    "    logging.warning(f\"Column '{column}' is fully null.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44a954a9-36e2-42c0-beea-2637dd0f7a6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create a master data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b403e50-eed8-4241-ad32-e90d4da21931",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "master_df = order_df.join(customer_df, on=\"Customer ID\", how=\"inner\").join(product_df, on=\"Product ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6a38b1-8579-4692-bbc7-a76979920913",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an enriched table for customers and products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f4177c4-e5c0-4965-a1c4-a2767eb0dd76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by \"Customer Name\" and \"Product Name\" and count occurrences\n",
    "customer_product_counts = master_df.groupBy(\"Customer Name\", \"Product Name\").count()\n",
    "\n",
    "# Add a new column for the count\n",
    "customer_product_counts = customer_product_counts.withColumn(\"Count\", F.col(\"count\"))\n",
    "customer_product_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eb57755-0219-4f55-b323-022c15418183",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(customer_product_counts) == True\n",
    "    assert checkColumnExists(customer_product_counts,[\"Customer Name\", \"Product Name\",\"Count\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f0a3e96-3eb6-4744-9de6-b47c56dfba59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(customer_product_counts, outputbucket, 'customer_product_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aa9674a-d73c-4786-ab6f-bf5265b38f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an enriched table which has\n",
    "1. order information \n",
    "    1. Profit rounded to 2 decimal places\n",
    "2. Customer name and country\n",
    "3. Product category and sub category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9beaa6aa-af98-47c0-93a1-a2c9b6c77231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "order_info = master_df.select('Order ID','Profit','Customer Name','Country','Category','Sub-Category')\n",
    "order_info = order_info.select(round(order_info[\"Profit\"], 2).alias(\"Profit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39a00d56-e7b2-483d-833d-a30eb5f1a13a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(order_info) == True\n",
    "    assert checkColumnExists(order_info, [\"Order ID\", \"Profit\",\"Customer Name\",\"Country\",\"Category\",\"Sub-Category\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a66b0de-f662-4b99-8740-c38bb4a6e863",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(order_info, outputbucket, 'order_info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dbf62d8-3adc-413c-8485-2077a449c22f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an aggregate table that shows profit by \n",
    "1. Year\n",
    "2. Product Category\n",
    "3. Product Sub Category\n",
    "4. Customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "408f5e08-9198-4ae2-a952-55e6bd4703de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "master_df = master_df.withColumn(\"year\", year(\"Order Date\"))\n",
    "agg_df = master_df.withColumn(\"year\", year(\"Order Date\"))\n",
    "agg_df = agg_df.groupBy(\"year\",\"Category\", \"Sub-Category\", \"Customer Name\").sum(\"Profit\")\n",
    "\n",
    "agg_df = agg_df.withColumnRenamed(\"sum(Profit)\", \"Profit\")\n",
    "agg_df = agg_df.withColumn(\"Profit\", round(col(\"Profit\"), 2))\n",
    "agg_df = agg_df.orderBy(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7cfe1a3-5053-483c-9a1c-47dee09e6ce9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(agg_df) == True\n",
    "    assert checkColumnExists(agg_df, [\"year\", \"Category\",\"Sub-Category\",\"Customer Name\",\"Profit\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35a18473-0caf-4c2a-85d6-a19b400b4c29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(agg_df, outputbucket, 'agg_table_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dfd4d83-e1d5-40f6-b8aa-f32cb7117ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using SQL output the following aggregates\n",
    "1. Profit by Year\n",
    "2. Profit by Year + Product Category\n",
    "3. Profit by Customer\n",
    "4. Profit by Customer + Year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56f4cfbe-4db8-4996-9c73-ec14a80b2b68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586d2051-5dcb-4366-a442-ba3c83e30633",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the master_df as a temporary table\n",
    "master_df.createOrReplaceTempView(\"master_table\")\n",
    "\n",
    "# Query the master_table to get Profit by Year\n",
    "profit_by_year_df = spark.sql(\"SELECT year, ROUND(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY year ORDER BY year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b22232f7-a0f8-47d4-8167-f93dd3032299",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(profit_by_year_df) == True\n",
    "    assert checkColumnExists(profit_by_year_df, [\"year\", \"TotalProfit\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d43296ed-09b9-4321-8e93-419723ccf38a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(profit_by_year_df, outputbucket, 'profit_by_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cfcc73f-680a-41cd-8ff8-c40942ff43a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Year + Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c47e95e-8709-4769-89bf-b7df8a5fc0cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_year_category_df = spark.sql(\"SELECT year, Category, ROUND(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY year, Category ORDER BY year, Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b6fc275-3a52-49f6-a62f-2f4fbe4cd049",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(profit_by_year_category_df) == True\n",
    "    assert checkColumnExists(profit_by_year_category_df, [\"year\", \"Category\",\"TotalProfit\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd9abcfb-c4e1-41be-9496-9796066d5429",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(profit_by_year_category_df, outputbucket, 'profit_by_year_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c509621-73d5-4454-912f-fcbbfe76db4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fbc19ef-1631-4b4b-ade0-f6233da78d7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_customer_df = spark.sql(\"SELECT `Customer Name`, Round(SUM(Profit),2) AS TotalProfit FROM master_table GROUP BY `Customer Name` order by TotalProfit DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a60a8734-373d-4683-8742-fc54a944f229",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(profit_by_customer_df) == True\n",
    "    assert checkColumnExists(profit_by_customer_df, [\"Customer Name\",\"TotalProfit\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71e073dd-07cf-4858-b9c5-29b25c615797",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(profit_by_customer_df, outputbucket, 'profit_by_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd48412-c616-4d3c-8731-7e08fdf66293",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Profit by Customer + Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba6b2922-55c0-4809-a2d8-b089fec5bba8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profit_by_customer_year_df = spark.sql(\"SELECT `Customer Name`, year, Round(SUM(Profit), 2) AS TotalProfit FROM master_table GROUP BY `Customer Name`, year ORDER BY year, TotalProfit DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81549e85-dc4b-49a3-b409-c4a7e87d81fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the row count and columns in the data frame.\n",
    "if mode == 'Test':\n",
    "    assert checkRowCount(profit_by_customer_year_df) == True\n",
    "    assert checkColumnExists(profit_by_customer_year_df, [\"Customer Name\",\"year\",\"TotalProfit\"]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d8c2f16-d94f-4796-b5d5-4ebaa02e25e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the output to csv. if the mode is not Test\n",
    "if mode != 'Test':\n",
    "    writeToS3(profit_by_customer_year_df, outputbucket, 'profit_by_customer_year')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ecommerce_sale_data",
   "widgets": {
    "Mode": {
     "currentValue": "Test",
     "nuid": "ff530a68-f856-4a8e-a2be-b20d4a27fcba",
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "Test",
      "label": null,
      "name": "Mode",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "Test",
        "Dev",
        "Prod"
       ]
      }
     }
    },
    "customer_file": {
     "currentValue": "s3://ecomerce/customer.xlsx",
     "nuid": "03a0ee5a-29ca-4091-9a81-76c45f019218",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/customer.xlsx",
      "label": null,
      "name": "customer_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "order_file": {
     "currentValue": "s3://ecomerce/Order.json",
     "nuid": "04e427ec-d9a7-488e-85a8-0660a3bfa0ae",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/Order.json",
      "label": null,
      "name": "order_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "outputbucket": {
     "currentValue": "ecommerce/output",
     "nuid": "8089c6a3-c4c6-4a50-9120-30e1a8668a42",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ecommerce/output",
      "label": null,
      "name": "outputbucket",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "product_file": {
     "currentValue": "s3://ecomerce/product.csv",
     "nuid": "e8fdb093-097a-4a5e-8ce4-b61684984210",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://ecomerce/product.csv",
      "label": null,
      "name": "product_file",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
